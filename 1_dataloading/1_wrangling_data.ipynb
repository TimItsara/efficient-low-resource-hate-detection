{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13adda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from html import unescape\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbcb7d-80d9-42c9-b391-cf6e785ae5eb",
   "metadata": {},
   "source": [
    "## Load raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "751cc58c-ca94-42c7-b1bd-a1d1e23ebdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/2220965070.py:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  print(re.sub('\\.csv$', '', file))\n",
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/2220965070.py:8: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  df_dict[re.sub('\\.csv$', '', file)] = pd.read_csv(f\"{PATH}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bas19_es\n",
      "dyn21_en\n",
      "for19_pt\n",
      "fou18_en\n",
      "has19_hi\n",
      "has20_hi\n",
      "has21_hi\n",
      "ken20_en\n",
      "ous19_ar\n",
      "ous19_fr\n",
      "san20_it\n"
     ]
    }
   ],
   "source": [
    "df_dict = dict()\n",
    "\n",
    "PATH = \"../0_data/main/0_raw\"\n",
    "\n",
    "for file in sorted(os.listdir(PATH)):\n",
    "    if \"ipynb\" not in file:\n",
    "        print(re.sub('\\.csv$', '', file))\n",
    "        df_dict[re.sub('\\.csv$', '', file)] = pd.read_csv(f\"{PATH}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7ed05-5188-48b5-a2ca-338ebadd806b",
   "metadata": {},
   "source": [
    "## Reformat columns\n",
    "Need separate logic for different datasets. 1 is for hateful, 0 for non-hateful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13277bd-80b3-4664-854c-9067973ff9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/1583237372.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_dict[\"dyn21_en\"].label.replace({\"hate\":1, \"nothate\":0}, inplace=True)\n",
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/1583237372.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_dict[\"dyn21_en\"].label.replace({\"hate\":1, \"nothate\":0}, inplace=True)\n",
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/1583237372.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_dict[\"fou18_en\"].label.replace({'hateful': 1, \"abusive\": 0, \"normal\": 0, \"spam\": 0}, inplace = True)\n",
      "/var/folders/31/pb5329nd0sl5sgm6rlw3p6340000gn/T/ipykernel_32419/1583237372.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_dict[\"fou18_en\"].label.replace({'hateful': 1, \"abusive\": 0, \"normal\": 0, \"spam\": 0}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Dynabench 2021 / English\n",
    "df_dict[\"dyn21_en\"].label.replace({\"hate\":1, \"nothate\":0}, inplace=True)\n",
    "\n",
    "# Founta 2018 / English\n",
    "df_dict[\"fou18_en\"].label.replace({'hateful': 1, \"abusive\": 0, \"normal\": 0, \"spam\": 0}, inplace = True)\n",
    "\n",
    "# Kennedy 2020 / English\n",
    "df_dict[\"ken20_en\"].rename(columns={\"label_hate_maj\": \"label\"}, inplace=True)\n",
    "\n",
    "# Fortuna 2019 / Portuguese\n",
    "df_dict[\"for19_pt\"].rename(columns={\"hatespeech_comb\": \"label\"}, inplace=True)\n",
    "\n",
    "# Basile 2019 / Spanish\n",
    "df_dict[\"bas19_es\"].rename(columns={\"HS\": \"label\"}, inplace=True)\n",
    "\n",
    "# Sanguinetti 2020 / Italian\n",
    "df_dict[\"san20_it\"].rename(columns={\"hs\": \"label\"}, inplace=True)\n",
    "\n",
    "# Ousidhoum 2019 / Arabic & French\n",
    "for d in [\"ous19_ar\", \"ous19_fr\"]:\n",
    "    df_dict[d][\"label\"] = df_dict[d].sentiment.apply(lambda x: 1 if \"hateful\" in x else 0)\n",
    "    # text was already cleaned in a way that conflicts with our later cleaning, so we align it here\n",
    "    df_dict[d][\"text\"] = df_dict[d].tweet.apply(lambda x: x.replace(\"@url\", \"http\"))\n",
    "    \n",
    "# HASOC 19, 20 and 21 / Hindi\n",
    "for d in [\"has19_hi\", \"has20_hi\", \"has21_hi\"]:\n",
    "    df_dict[d][\"label\"] = df_dict[d].task_2.apply(lambda x: 1 if x==\"HATE\" else 0)\n",
    "    \n",
    "# drop redundant columns\n",
    "for dataset in df_dict:\n",
    "    if \"split\" in df_dict[dataset].columns:\n",
    "        df_dict[dataset] = df_dict[dataset][[\"text\", \"label\", \"split\"]]\n",
    "    else:\n",
    "        df_dict[dataset] = df_dict[dataset][[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb486c0-6d69-47de-ab40-1395cff48b78",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f2180b-49b9-4337-8bf6-918ae0fff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = unescape(text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_-]+\",'@user',text) # format expected by XLM-T\n",
    "    text = re.sub(r\"http\\S+\",'http',text) # format expected by XLM-T\n",
    "    text = re.sub(r\"\\n\",' ',text)\n",
    "    text = re.sub(r\"\\t\",' ',text)\n",
    "    text = text.replace(\"[URL]\", \"http\") # format expected by XLM-T\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset][\"text\"] = df_dict[dataset].text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab5775-1e3f-4b2e-9f04-5f896cd532f3",
   "metadata": {},
   "source": [
    "## Boost proportion of hate in English datasets to match Dynabench\n",
    "We are doing a first phase of fine-tuning on up to 20k entries in Dynabench. Dynabench has ca. 53% hate. The other English datasets have a lower proportion of hate so we drop non-hate to make the proportion more comparable at 20k entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41906fb5-a64e-4a90-95ab-ca685dec29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost Kennedy 2020 / English to have 50% hate (up from ca. 30%)\n",
    "df_dict[\"ken20_en\"] = pd.concat([df_dict[\"ken20_en\"][df_dict[\"ken20_en\"].label==1], df_dict[\"ken20_en\"][df_dict[\"ken20_en\"].label==0].sample(11596, random_state=123)]).sample(frac=1, random_state=123)\n",
    "\n",
    "# boost Founta 2018 / English to have 22% hate, which is max possible (up from ca. 5%)\n",
    "df_dict[\"fou18_en\"] = pd.concat([df_dict[\"fou18_en\"][df_dict[\"fou18_en\"].label==1], df_dict[\"fou18_en\"][df_dict[\"fou18_en\"].label==0].sample(17600, random_state=123)]).sample(frac=1, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f11a2-57a3-4f6e-85d8-1e9964695e8a",
   "metadata": {},
   "source": [
    "## Show descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf6ea87-7c69-4ead-88e6-7dd675650ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAS19_ES\n",
      "6600 entries, of which 2739 (41.50%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>@user Me flipaüòç Me tienes que ense√±ar a hacer pelo me cago en la puta JAJAJA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>¬øQue harian los hombres sin las mujeres? Pues domesticar otro animal y esta vez no ense√±arle a hablar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Que no es presunto üêç @user que ESCORIAüòà es CULPABLE del ASESINATO,DESAPARICION,SECUESTRO Y VIOLACI√ìN de #DianaQuer angelico üòìüå∑üíïüêæüåõ D.E.P que este ESCORIAüòàq su trastorno solo es #HijoPutismoAgudo va a pagarlo üòàüòà #TodasSomosDiana üíïüêæüåõ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>Hasta ahora me vi el cap√≠tulo de #TWD y solo tengo que decir que Eugene es un hijo de puta que merec√≠a morir en lugar de Carl. Ah y qu√© adoro a Maggie obviamente no m√°s que a Carol.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>El curioso caso del hombre que solo ve machismo si el acusado es un √°rabe.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                        text  \\\n",
       "2438                                                                                                                                                            @user Me flipaüòç Me tienes que ense√±ar a hacer pelo me cago en la puta JAJAJA   \n",
       "4938                                                                                                                                  ¬øQue harian los hombres sin las mujeres? Pues domesticar otro animal y esta vez no ense√±arle a hablar.   \n",
       "295   Que no es presunto üêç @user que ESCORIAüòà es CULPABLE del ASESINATO,DESAPARICION,SECUESTRO Y VIOLACI√ìN de #DianaQuer angelico üòìüå∑üíïüêæüåõ D.E.P que este ESCORIAüòàq su trastorno solo es #HijoPutismoAgudo va a pagarlo üòàüòà #TodasSomosDiana üíïüêæüåõ   \n",
       "2765                                                   Hasta ahora me vi el cap√≠tulo de #TWD y solo tengo que decir que Eugene es un hijo de puta que merec√≠a morir en lugar de Carl. Ah y qu√© adoro a Maggie obviamente no m√°s que a Carol.   \n",
       "3865                                                                                                                                                              El curioso caso del hombre que solo ve machismo si el acusado es un √°rabe.   \n",
       "\n",
       "      label  \n",
       "2438      0  \n",
       "4938      1  \n",
       "295       0  \n",
       "2765      0  \n",
       "3865      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DYN21_EN\n",
      "41144 entries, of which 22175 (53.90%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22247</th>\n",
       "      <td>You see, children imitate society and we live in a time where falsehoods are embraced in the name of pushing a narrative. Equality of opportunity? Where?</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22568</th>\n",
       "      <td>All women and men and others are looking for is someone to provide for us.</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18435</th>\n",
       "      <td>who is truly suffering? Those of you who need to be lead by leaders or those who are waiting for the next hand out jerked off expired food ?</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>I am a big fat curry muncher and would eat it over anything!</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>Today I feel like I have to mention how muslims are influencing the level of wonderful things in the world. By that I mean negatively  of course since muslims are basically just pigs to lookat</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   text  \\\n",
       "22247                                         You see, children imitate society and we live in a time where falsehoods are embraced in the name of pushing a narrative. Equality of opportunity? Where?   \n",
       "22568                                                                                                                        All women and men and others are looking for is someone to provide for us.   \n",
       "18435                                                      who is truly suffering? Those of you who need to be lead by leaders or those who are waiting for the next hand out jerked off expired food ?   \n",
       "8394                                                                                                                                       I am a big fat curry muncher and would eat it over anything!   \n",
       "8332   Today I feel like I have to mention how muslims are influencing the level of wonderful things in the world. By that I mean negatively  of course since muslims are basically just pigs to lookat   \n",
       "\n",
       "       label  split  \n",
       "22247      0   test  \n",
       "22568      0    dev  \n",
       "18435      0  train  \n",
       "8394       0  train  \n",
       "8332       1  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR19_PT\n",
      "5670 entries, of which 1788 (31.53%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>Desconfio que a NASA s√≥ n√£o anunciou ter descoberto vida num dos 7 planetas com receio que o Trump mandasse construir outro muro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>RT @user: CALMA CACHORRO, ELA AINDA N√ÉO VIROU RA√á√ÉO #PAZ http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>@user Pra ser mulher hoje em dia e aguentar o movimento feminista...tem que ser muito macho. kkkkk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>@user T√¥ esperando a sapat√£o fazer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>RT @user: o cara entrevistou o @user ficou igual uma putinha concordando e agora lan√ßa essa legenda canalha. Que arrombado _</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                     text  \\\n",
       "1087  Desconfio que a NASA s√≥ n√£o anunciou ter descoberto vida num dos 7 planetas com receio que o Trump mandasse construir outro muro...   \n",
       "4421                                                                        RT @user: CALMA CACHORRO, ELA AINDA N√ÉO VIROU RA√á√ÉO #PAZ http   \n",
       "260                                    @user Pra ser mulher hoje em dia e aguentar o movimento feminista...tem que ser muito macho. kkkkk   \n",
       "5661                                                                                                   @user T√¥ esperando a sapat√£o fazer   \n",
       "4230         RT @user: o cara entrevistou o @user ficou igual uma putinha concordando e agora lan√ßa essa legenda canalha. Que arrombado _   \n",
       "\n",
       "      label  \n",
       "1087      0  \n",
       "4421      1  \n",
       "260       1  \n",
       "5661      1  \n",
       "4230      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOU18_EN\n",
      "22565 entries, of which 4965 (22.00%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>#cnageeks AMERICAN GODS Character Promos Spotlight Shadow &amp; Laura Moon, Mr. Wednesday, And Mad Sweeney http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16935</th>\n",
       "      <td>RT @user: Omg im so ugly April fools bitch you thought</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38733</th>\n",
       "      <td>One (1) Gen Ad ticket for day 1 is also another option please DM/@ me if you have! Thank you! #BTSWingsTourManila http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>RT @user: Look at this fucking asshole: http http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64597</th>\n",
       "      <td>@user U know the episode when Jan invites him and Pam to a DINNER PARTY that is my fucking life rn pulse‚Ä¶ http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         text  \\\n",
       "10688             #cnageeks AMERICAN GODS Character Promos Spotlight Shadow & Laura Moon, Mr. Wednesday, And Mad Sweeney http   \n",
       "16935                                                                  RT @user: Omg im so ugly April fools bitch you thought   \n",
       "38733  One (1) Gen Ad ticket for day 1 is also another option please DM/@ me if you have! Thank you! #BTSWingsTourManila http   \n",
       "20143                                                                       RT @user: Look at this fucking asshole: http http   \n",
       "64597          @user U know the episode when Jan invites him and Pam to a DINNER PARTY that is my fucking life rn pulse‚Ä¶ http   \n",
       "\n",
       "       label  \n",
       "10688      0  \n",
       "16935      0  \n",
       "38733      1  \n",
       "20143      0  \n",
       "64597      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAS19_HI\n",
      "5983 entries, of which 746 (12.47%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>‡§Ö‡§¨ ‡§ï‡§π‡§æ‡§Å ‡§Æ‡§∞ ‡§ó‡§Ø‡§æ...‡§∂‡§æ‡§Ç‡§§‡§ø‡§¶‡•Ç‡§§ ‡§¨‡•ã‡§≤‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§ó‡•à‡§Ç‡§ó...‡§Ø‡§π ‡§ú‡§º‡§Æ‡§æ‡§§ ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à ‡§≠‡§æ‡§∞‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•Ä, ‡§®‡§æ ‡§π‡•ã‡§ó‡•Ä‡•§ ‡§Ø‡§π ‡§ï‡§ü‡•Å ‡§∏‡§ü‡•Ä‡§ï ‡§∏‡§ö‡•ç‡§ö‡§æ‡§à ‡§π‡•à‡•§ ‡§´‡§ø‡§∞ ‡§≠‡•Ä ‡§Ø‡§π ‡§∏‡•Å‡§Ö‡§∞ ‡§ú‡§º‡§Æ‡§æ‡§§ ‡§´‡§≤ ‡§´‡•Ç‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§ó‡§Ç‡§¶‡§ó‡•Ä ‡§∞‡§æ‡§ú‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§µ‡§ú‡§π ‡§∏‡•á ‡§´‡•à‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§ú‡§ø‡§∏‡§ï‡•Ä ‡§¨‡§¶‡§¨‡•Ç ‡§∏‡•á ‡§π‡§Æ‡•á‡§∂‡§æ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§ñ‡§º‡§∞‡§æ‡§¨ ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>‡§ê‡§∏‡§æ ‡§Ö‡§ó‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§®‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§Æ‡§ï‡§¨‡§∞‡•á ‡§™‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§§‡•ã ‡§§‡•Ç ‡§π‡•Ä ‡§∞‡§Ç‡§°‡•Ä ‡§ú‡•ã‡§∞ ‡§ú‡•ã‡§∞ ‡§∏‡•á ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ‡§§‡•Ä ‡§Ü‡§∞ ‡§è‡§∏ ‡§è‡§∏ ‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§®‡•á ‡§¨‡§ú‡§∞‡§Ç‡§ó ‡§¶‡§≤ ‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§®‡•á ‡§ï‡§ø‡§Ø‡§æ   ‡§î‡§∞ ‡§∏‡•Ç‡§Ö‡§∞ ‡§ï‡•Ä ‡§î‡§≤‡§æ‡§¶ ‡§¶‡•á‡§Ç ‡§§‡•Å‡§ù‡•á ‡§∂‡§∞‡§æ‡§∞‡§§‡•Ä ‡§§‡§§‡•ç‡§µ ‡§¶‡•á‡§ñ‡§®‡•á ‡§≤‡§ó‡•á ‡§π‡§∞‡§æ‡§Æ ‡§ï‡•Ä ‡§ú‡§®‡•Ä</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>‡§ï‡§Æ‡§≤‡§®‡§æ‡§• ‡§®‡•á ‡§Æ‡§æ‡§®‡§æ~‡§ï‡§∞‡•ç‡§ú‡§Æ‡§æ‡§´‡•Ä ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§™‡§∞ ‡§π‡•Å‡§Ü ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ  ‡§¶‡•ã‡§∑‡§ø‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§π‡•ã‡§ó‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§∞‡§µ‡§æ‡§à     ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§™‡§∞ ‡§´‡§∞‡•ç‡§ú‡•Ä ‡§™‡•ç‡§∞‡§ï‡§∞‡§£ ‡§¨‡§®‡§æ‡§ï‡§∞ #‡§§‡•Ä‡§®_‡§π‡§ú‡§æ‡§∞_‡§ï‡§∞‡•ã‡§°‡§º_‡§∞‡•Å‡§™‡§è_‡§ï‡§æ_‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ_‡§π‡•Å‡§Ü ‡§π‡•à    #‡§ï‡§Æ‡•Ä‡§®‡•á ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§Æ‡§§ ‡§¨‡§®‡§æ    ‡§∏‡§¨ #‡§§‡•á‡§∞‡§æ_‡§π‡•Ä_‡§ï‡§ø‡§Ø‡§æ_‡§ß‡§∞‡§æ ‡§π‡•à    ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§µ‡§æ‡§π‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§ñ‡§æ‡§ï ‡§π‡•ã‡§ó‡•Ä ???  ‡§ú‡§¨ ‡§§‡•á‡§∞‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡•Ä ‡§ñ‡§§‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡•à</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>‡§Ø‡•á human rights ‡§î‡§∞ secularism ‡§ï‡•Ä ‡§®‡§æ‡§ú‡§æ‡§Ø‡§ú ‡§î‡§≤‡§æ‡§¶‡•á‡§Ç ‡§Ö‡§¨ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à  ‡§è‡§ï ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§ï‡•Ä ‡§ó‡§æ‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§Æ‡•Å‡§Ç‡§π ‡§°‡§æ‡§≤ ‡§ï‡•á ‡§∏‡•ã ‡§ó‡§Ø‡•á ‡§π‡•à‡§Ç  #TempleTerrorAttack</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>‡§¨‡§π‡•Å‡§§ ‡§¨‡§π‡•Å‡§§ ‡§∂‡•Å‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡•§    ‡§Ø‡§π ‡§ñ‡•ç‡§Ø‡§æ‡§≤‡•á ‡§ñ‡§æ‡§Æ ‡§π‡•à,‡§ñ‡•Ç‡§¨‡§∏‡•Ç‡§∞‡§§‡•Ä ‡§ö‡•á‡§π‡§∞‡•á ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à‡•§  ‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•ã ‡§§‡•ã,,‡§∏‡•Ä‡§∞‡§§ ‡§≠‡•Ä ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§    ‡§®‡§à‡§Æ  #‡§¨‡§ú‡§º‡•ç‡§Æ #‡§π‡§ø‡§Ç‡§¶‡•Ä_‡§∂‡§¨‡•ç‡§¶ #‡§¨‡§ú‡§º‡•ç‡§Æ_‡§è_‡§á‡§ñ‡§º‡§≤‡§æ‡§∏   @user @user   @user @user   @user @user   @user @user</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                      text  \\\n",
       "5021                     ‡§Ö‡§¨ ‡§ï‡§π‡§æ‡§Å ‡§Æ‡§∞ ‡§ó‡§Ø‡§æ...‡§∂‡§æ‡§Ç‡§§‡§ø‡§¶‡•Ç‡§§ ‡§¨‡•ã‡§≤‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§ó‡•à‡§Ç‡§ó...‡§Ø‡§π ‡§ú‡§º‡§Æ‡§æ‡§§ ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à ‡§≠‡§æ‡§∞‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•Ä, ‡§®‡§æ ‡§π‡•ã‡§ó‡•Ä‡•§ ‡§Ø‡§π ‡§ï‡§ü‡•Å ‡§∏‡§ü‡•Ä‡§ï ‡§∏‡§ö‡•ç‡§ö‡§æ‡§à ‡§π‡•à‡•§ ‡§´‡§ø‡§∞ ‡§≠‡•Ä ‡§Ø‡§π ‡§∏‡•Å‡§Ö‡§∞ ‡§ú‡§º‡§Æ‡§æ‡§§ ‡§´‡§≤ ‡§´‡•Ç‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§ó‡§Ç‡§¶‡§ó‡•Ä ‡§∞‡§æ‡§ú‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§µ‡§ú‡§π ‡§∏‡•á ‡§´‡•à‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§ú‡§ø‡§∏‡§ï‡•Ä ‡§¨‡§¶‡§¨‡•Ç ‡§∏‡•á ‡§π‡§Æ‡•á‡§∂‡§æ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§ñ‡§º‡§∞‡§æ‡§¨ ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§   \n",
       "638                                                                                     ‡§ê‡§∏‡§æ ‡§Ö‡§ó‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§®‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§Æ‡§ï‡§¨‡§∞‡•á ‡§™‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§§‡•ã ‡§§‡•Ç ‡§π‡•Ä ‡§∞‡§Ç‡§°‡•Ä ‡§ú‡•ã‡§∞ ‡§ú‡•ã‡§∞ ‡§∏‡•á ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ‡§§‡•Ä ‡§Ü‡§∞ ‡§è‡§∏ ‡§è‡§∏ ‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§®‡•á ‡§¨‡§ú‡§∞‡§Ç‡§ó ‡§¶‡§≤ ‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§®‡•á ‡§ï‡§ø‡§Ø‡§æ   ‡§î‡§∞ ‡§∏‡•Ç‡§Ö‡§∞ ‡§ï‡•Ä ‡§î‡§≤‡§æ‡§¶ ‡§¶‡•á‡§Ç ‡§§‡•Å‡§ù‡•á ‡§∂‡§∞‡§æ‡§∞‡§§‡•Ä ‡§§‡§§‡•ç‡§µ ‡§¶‡•á‡§ñ‡§®‡•á ‡§≤‡§ó‡•á ‡§π‡§∞‡§æ‡§Æ ‡§ï‡•Ä ‡§ú‡§®‡•Ä   \n",
       "2119  ‡§ï‡§Æ‡§≤‡§®‡§æ‡§• ‡§®‡•á ‡§Æ‡§æ‡§®‡§æ~‡§ï‡§∞‡•ç‡§ú‡§Æ‡§æ‡§´‡•Ä ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§™‡§∞ ‡§π‡•Å‡§Ü ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ  ‡§¶‡•ã‡§∑‡§ø‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§π‡•ã‡§ó‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§∞‡§µ‡§æ‡§à     ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§™‡§∞ ‡§´‡§∞‡•ç‡§ú‡•Ä ‡§™‡•ç‡§∞‡§ï‡§∞‡§£ ‡§¨‡§®‡§æ‡§ï‡§∞ #‡§§‡•Ä‡§®_‡§π‡§ú‡§æ‡§∞_‡§ï‡§∞‡•ã‡§°‡§º_‡§∞‡•Å‡§™‡§è_‡§ï‡§æ_‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ_‡§π‡•Å‡§Ü ‡§π‡•à    #‡§ï‡§Æ‡•Ä‡§®‡•á ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§Æ‡§§ ‡§¨‡§®‡§æ    ‡§∏‡§¨ #‡§§‡•á‡§∞‡§æ_‡§π‡•Ä_‡§ï‡§ø‡§Ø‡§æ_‡§ß‡§∞‡§æ ‡§π‡•à    ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§µ‡§æ‡§π‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§ñ‡§æ‡§ï ‡§π‡•ã‡§ó‡•Ä ???  ‡§ú‡§¨ ‡§§‡•á‡§∞‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡•Ä ‡§ñ‡§§‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡•à   \n",
       "3140                                                                                                                                           ‡§Ø‡•á human rights ‡§î‡§∞ secularism ‡§ï‡•Ä ‡§®‡§æ‡§ú‡§æ‡§Ø‡§ú ‡§î‡§≤‡§æ‡§¶‡•á‡§Ç ‡§Ö‡§¨ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à  ‡§è‡§ï ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§ï‡•Ä ‡§ó‡§æ‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§Æ‡•Å‡§Ç‡§π ‡§°‡§æ‡§≤ ‡§ï‡•á ‡§∏‡•ã ‡§ó‡§Ø‡•á ‡§π‡•à‡§Ç  #TempleTerrorAttack   \n",
       "497                                                        ‡§¨‡§π‡•Å‡§§ ‡§¨‡§π‡•Å‡§§ ‡§∂‡•Å‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡•§    ‡§Ø‡§π ‡§ñ‡•ç‡§Ø‡§æ‡§≤‡•á ‡§ñ‡§æ‡§Æ ‡§π‡•à,‡§ñ‡•Ç‡§¨‡§∏‡•Ç‡§∞‡§§‡•Ä ‡§ö‡•á‡§π‡§∞‡•á ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à‡•§  ‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•ã ‡§§‡•ã,,‡§∏‡•Ä‡§∞‡§§ ‡§≠‡•Ä ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§    ‡§®‡§à‡§Æ  #‡§¨‡§ú‡§º‡•ç‡§Æ #‡§π‡§ø‡§Ç‡§¶‡•Ä_‡§∂‡§¨‡•ç‡§¶ #‡§¨‡§ú‡§º‡•ç‡§Æ_‡§è_‡§á‡§ñ‡§º‡§≤‡§æ‡§∏   @user @user   @user @user   @user @user   @user @user   \n",
       "\n",
       "      label  split  \n",
       "5021      0   test  \n",
       "638       0  train  \n",
       "2119      0  train  \n",
       "3140      0  train  \n",
       "497       0  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAS20_HI\n",
      "4232 entries, of which 347 (8.20%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>‡§ú‡•ã ‡§¶‡•á‡§∂ ‡§π‡§ø‡§§ ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§ó‡§æ ‡§µ‡§π‡•Ä‡§Ç ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§™‡§∞ ‡§∞‡§æ‡§ú ‡§ï‡§∞‡•á‡§ó‡§æ</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>RT @user: ‡§§‡§¨ ‡§§‡•ã ‡§¨‡§¨‡•Å‡§Ü ‡§≠‡•Ä ‡§¨‡•Å‡§Ü ‡§ï‡•á ‡§â‡§∏ ‡§ò‡•ã‡§ü‡§æ‡§≤‡•á ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§æ‡§®‡•á ‡§ï‡•á ‡§ê‡§≤‡§æ‡§® ‡§ï‡§∞‡§ï‡•á ‡§ó‡§è ‡§•‡•á‡•§   ‡§≤‡•á‡§ï‡§ø‡§® ‡§π‡•Å‡§Ü ‡§ï‡•ç‡§Ø‡§æ?  ‡§¨‡•Å‡§Ü ‡§î‡§∞ ‡§¨‡§¨‡•Å‡§Ü ‡§®‡•á ‡§Ü‡§ú ‡§ñ‡•Å‡§¶ ‡§π‡§æ‡§• ‡§Æ‡§ø‡§≤‡§æ ‡§≤‡§ø‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>UNSC ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§∏‡•Ç‡§¶ ‡§Ö‡§ú‡§π‡§∞ ‡§ï‡•ã global terrorist ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ ‡§Ö‡§¨ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ï‡§à ‡§≤‡•ã‡§ó ‡§á‡§∏‡•á ‡§≠‡•Ä BJP ‡§ï‡•Ä ‡§ö‡§æ‡§≤ ‡§¨‡§§‡§æ ‡§¶‡•á‡•§ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ø‡•á ‡§≤‡•ã‡§ó ‡§™‡•Ç‡§õ ‡§≤‡•á ‡§ï‡§ø ‡§ö‡•Å‡§®‡§æ‡§µ ‡§¶‡•å‡§∞‡§æ‡§® ‡§π‡•Ä ‡§ï‡•ç‡§Ø‡•ã‡§Ç UNSC ‡§®‡•á ‡§Ø‡•á ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡§ø‡•§ ‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§¶‡§§ ‡§∏‡•á ‡§¨‡§æ‡§ú ‡§•‡•ã‡§°‡§º‡•Ä ‡§®‡§æ ‡§Ü‡§Ø‡•á‡§Ç‡§ó‡•á ‡§Ø‡•á‡•§ #BJP4India #beatAjhar ##BeatTerror #BeatPakistan #Badla</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>@user ‡§Ø‡•á ‡§§‡•ã ‡§¨‡§∏ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä, ‡§π‡•á‡§≤‡§ø‡§ï‡•â‡§™‡•ç‡§ü‡§∞ ‡§Æ‡•á‡§Ç ‡§ú‡§¨ ‡§∏‡§æ‡§π‡•á‡§¨ ‡§ï‡•ã ‡§†‡§Ç‡§° ‡§≤‡§ó‡§§‡•Ä ‡§•‡•Ä ‡§§‡•ã ‡§µ‡•ã ‡§™‡§Ç‡§ñ‡§æ ‡§ë‡§´ ‡§ï‡§∞ ‡§¶‡•á‡§§‡•á ‡§•‡•á !! ‡§´‡•ç‡§Ø‡•Ç‡§≤ ‡§≠‡•Ä ‡§¨‡§ö ‡§ú‡§æ‡§§‡•Ä ‡§•‡•Ä ‡§î‡§∞ ‡§†‡§Ç‡§° ‡§∏‡•á ‡§≠‡•Ä ‡§õ‡•Å‡§ü‡§ï‡§æ‡§∞‡§æ üòÇüòÇüòâüòâ</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>@user @user @user ‡§µ‡§æ‡§π ‡§∞‡•á ‡§§‡•á‡§∞‡•Ä ‡§Æ‡§æ‡§Ç ‡§ï‡•ã ‡§ö‡•ã‡§¶‡•Ç ‡§≠‡§°‡§º‡§µ‡•á ‡§µ‡§æ‡§π üòù</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                          text  \\\n",
       "846                                                                                                                                                                                                                                           ‡§ú‡•ã ‡§¶‡•á‡§∂ ‡§π‡§ø‡§§ ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§ó‡§æ ‡§µ‡§π‡•Ä‡§Ç ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§™‡§∞ ‡§∞‡§æ‡§ú ‡§ï‡§∞‡•á‡§ó‡§æ   \n",
       "238                                                                                                                                                           RT @user: ‡§§‡§¨ ‡§§‡•ã ‡§¨‡§¨‡•Å‡§Ü ‡§≠‡•Ä ‡§¨‡•Å‡§Ü ‡§ï‡•á ‡§â‡§∏ ‡§ò‡•ã‡§ü‡§æ‡§≤‡•á ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§æ‡§®‡•á ‡§ï‡•á ‡§ê‡§≤‡§æ‡§® ‡§ï‡§∞‡§ï‡•á ‡§ó‡§è ‡§•‡•á‡•§   ‡§≤‡•á‡§ï‡§ø‡§® ‡§π‡•Å‡§Ü ‡§ï‡•ç‡§Ø‡§æ?  ‡§¨‡•Å‡§Ü ‡§î‡§∞ ‡§¨‡§¨‡•Å‡§Ü ‡§®‡•á ‡§Ü‡§ú ‡§ñ‡•Å‡§¶ ‡§π‡§æ‡§• ‡§Æ‡§ø‡§≤‡§æ ‡§≤‡§ø‚Ä¶   \n",
       "1342  UNSC ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§∏‡•Ç‡§¶ ‡§Ö‡§ú‡§π‡§∞ ‡§ï‡•ã global terrorist ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ ‡§Ö‡§¨ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ï‡§à ‡§≤‡•ã‡§ó ‡§á‡§∏‡•á ‡§≠‡•Ä BJP ‡§ï‡•Ä ‡§ö‡§æ‡§≤ ‡§¨‡§§‡§æ ‡§¶‡•á‡•§ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ø‡•á ‡§≤‡•ã‡§ó ‡§™‡•Ç‡§õ ‡§≤‡•á ‡§ï‡§ø ‡§ö‡•Å‡§®‡§æ‡§µ ‡§¶‡•å‡§∞‡§æ‡§® ‡§π‡•Ä ‡§ï‡•ç‡§Ø‡•ã‡§Ç UNSC ‡§®‡•á ‡§Ø‡•á ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡§ø‡•§ ‡§Ö‡§™‡§®‡•Ä ‡§Ü‡§¶‡§§ ‡§∏‡•á ‡§¨‡§æ‡§ú ‡§•‡•ã‡§°‡§º‡•Ä ‡§®‡§æ ‡§Ü‡§Ø‡•á‡§Ç‡§ó‡•á ‡§Ø‡•á‡•§ #BJP4India #beatAjhar ##BeatTerror #BeatPakistan #Badla   \n",
       "1038                                                                                                                                                  @user ‡§Ø‡•á ‡§§‡•ã ‡§¨‡§∏ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä, ‡§π‡•á‡§≤‡§ø‡§ï‡•â‡§™‡•ç‡§ü‡§∞ ‡§Æ‡•á‡§Ç ‡§ú‡§¨ ‡§∏‡§æ‡§π‡•á‡§¨ ‡§ï‡•ã ‡§†‡§Ç‡§° ‡§≤‡§ó‡§§‡•Ä ‡§•‡•Ä ‡§§‡•ã ‡§µ‡•ã ‡§™‡§Ç‡§ñ‡§æ ‡§ë‡§´ ‡§ï‡§∞ ‡§¶‡•á‡§§‡•á ‡§•‡•á !! ‡§´‡•ç‡§Ø‡•Ç‡§≤ ‡§≠‡•Ä ‡§¨‡§ö ‡§ú‡§æ‡§§‡•Ä ‡§•‡•Ä ‡§î‡§∞ ‡§†‡§Ç‡§° ‡§∏‡•á ‡§≠‡•Ä ‡§õ‡•Å‡§ü‡§ï‡§æ‡§∞‡§æ üòÇüòÇüòâüòâ   \n",
       "3798                                                                                                                                                                                                                                     @user @user @user ‡§µ‡§æ‡§π ‡§∞‡•á ‡§§‡•á‡§∞‡•Ä ‡§Æ‡§æ‡§Ç ‡§ï‡•ã ‡§ö‡•ã‡§¶‡•Ç ‡§≠‡§°‡§º‡§µ‡•á ‡§µ‡§æ‡§π üòù   \n",
       "\n",
       "      label  split  \n",
       "846       0  train  \n",
       "238       0  train  \n",
       "1342      1  train  \n",
       "1038      0  train  \n",
       "3798      0   test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAS21_HI\n",
      "4594 entries, of which 566 (12.32%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>‡§ï‡§≤ ‡§ï‡•ã‡§à ‡§ï‡§π ‡§∞‡§π‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§¶‡•á‡§∂ ‡•™‡•¶‡•¶‡§∏‡§æ‡§≤ ‡§™‡•Ä‡§õ‡•á ‡§ö‡§≤‡§æ ‡§ó‡§Ø‡§æ... ‡§Æ‡•à‡§®‡•á ‡§ï‡§π‡§æ ‡§¨‡§∏ ‡•® ‡§∏‡§æ‡§≤ ‡§î‡§∞ ‡§∞‡•Å‡§ï‡•ã ‡§∏‡•Ä‡§ß‡•á ‡§§‡•ç‡§∞‡•á‡§§‡§æ ‡§Ø‡•Å‡§ó ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§Ç‡§ó‡•á ‡§Ü‡§™!  ---‡§ó‡§ú‡§¨ ‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§π‡•à‡§Ç!</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>@user ‡§Æ‡•ã‡§¶‡•Ä ‡§§‡•Å‡§Æ ‡§á‡§∏‡•ç‡§§‡•Ä‡§´‡§æ ‡§¶‡•ã ‡§π‡§Æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§∏‡§æ‡§• ‡§π‡•à #ResignModi  #Resign_PM_Modi  #ModiHataoDeshBachao http</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>@user @user @user @user @user @user @user @user @user ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç, ‡§Ü‡§ì ‡§π‡§Æ ‡§∏‡§¨ ‡§∏‡§∞‡•ç‡§µ‡§∏‡§Æ‡•ç‡§Æ‡§§‡§ø ‡§∏‡•á ‡§Æ‡§π‡§æ‡§® ‡§Ö‡§∞‡•ç‡§•‡§∂‡§æ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä, ‡§ß‡•Å‡§∞‡§Ç‡§ß‡§∞ ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï, ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡§Ø‡§Ç‡§ï‡§∞ ‡§∏‡§µ‡§∞‡•ç‡§£-‡§¶‡§≤‡§ø‡§§ ‡§Æ‡§∏‡•Ä‡§π‡§æ #‡§ö‡•Å‡§¶‡§ø‡§§ ‡§∞‡§æ‡§ú ‡§ú‡•Ä ‡§ï‡•ã ‡§ñ‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ #‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§è‡§µ‡§Ç #‡§™‡§≤‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡§≤‡•Ä ‡§¨‡§®‡§æ‡§è‡§Ç !!üôè \"‡§∏‡§≠‡•Ä #‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§è‡§Ç ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§\" #‡§â‡§¶‡§ø‡§§_‡§∞‡§æ‡§ú_‡§ï‡•ã_‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑_‡§¨‡§®‡§æ‡§ì_‡§¨‡•á @user  #CovidVaccine http</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>2 /2ll‡§ï‡§π‡§æ‡§Å ‡§π‡•à? ‡§∏‡§®‡§¶ ‡§∞‡§π‡•á ‡§ï‡§ø ‡§Ø‡§π‡•Ä ‡§Ü‡§∞‡§ú‡•á‡§°‡•Ä ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§π‡•Ä ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Ü‡§∞‡§ú‡•á‡§°‡•Ä ‡§ï‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§Æ‡•Ä‡§∞‡§æ‡§® ‡§π‡•à‡§¶‡§∞ ‡§ï‡•Ä ‡§ó‡§ø‡§∞‡§´‡•ç‡§§‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§∞‡§ø‡§π‡§æ‡§à ‡§ï‡•á ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§ö‡•Å‡§™ ‡§π‡•à‡•§ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡•Ä ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•á‡§∞‡•á ‡§¨‡•Å‡§∞‡•á ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§®‡§π‡•Ä‡§Ç ‡§§‡•ã ‡§π‡§Æ ‡§Ü‡§™‡§ï‡§æ ‡§ù‡§Ç‡§°‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§¢‡•ã‡§è‡§Ç?  @user  @user   #JusticeForShahabuddin</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§∏‡§ø‡§µ‡§æ‡§® ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§ï‡§∞ ‡§¶‡•Ä   ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§™‡§®‡•á ‡§∏‡§ø‡§µ‡§æ‡§® ‡§ï‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§® ‡§Æ‡§ø‡§≤ ‡§∏‡§ï‡•Ä üò≠  #JusticeForShahabuddin</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "2721                                                                                                                                                                                          ‡§ï‡§≤ ‡§ï‡•ã‡§à ‡§ï‡§π ‡§∞‡§π‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§¶‡•á‡§∂ ‡•™‡•¶‡•¶‡§∏‡§æ‡§≤ ‡§™‡•Ä‡§õ‡•á ‡§ö‡§≤‡§æ ‡§ó‡§Ø‡§æ... ‡§Æ‡•à‡§®‡•á ‡§ï‡§π‡§æ ‡§¨‡§∏ ‡•® ‡§∏‡§æ‡§≤ ‡§î‡§∞ ‡§∞‡•Å‡§ï‡•ã ‡§∏‡•Ä‡§ß‡•á ‡§§‡•ç‡§∞‡•á‡§§‡§æ ‡§Ø‡•Å‡§ó ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§Ç‡§ó‡•á ‡§Ü‡§™!  ---‡§ó‡§ú‡§¨ ‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§π‡•à‡§Ç!   \n",
       "2560                                                                                                                                                                                                                @user ‡§Æ‡•ã‡§¶‡•Ä ‡§§‡•Å‡§Æ ‡§á‡§∏‡•ç‡§§‡•Ä‡§´‡§æ ‡§¶‡•ã ‡§π‡§Æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§∏‡§æ‡§• ‡§π‡•à #ResignModi  #Resign_PM_Modi  #ModiHataoDeshBachao http   \n",
       "511   @user @user @user @user @user @user @user @user @user ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç, ‡§Ü‡§ì ‡§π‡§Æ ‡§∏‡§¨ ‡§∏‡§∞‡•ç‡§µ‡§∏‡§Æ‡•ç‡§Æ‡§§‡§ø ‡§∏‡•á ‡§Æ‡§π‡§æ‡§® ‡§Ö‡§∞‡•ç‡§•‡§∂‡§æ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä, ‡§ß‡•Å‡§∞‡§Ç‡§ß‡§∞ ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï, ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®, ‡§≠‡§Ø‡§Ç‡§ï‡§∞ ‡§∏‡§µ‡§∞‡•ç‡§£-‡§¶‡§≤‡§ø‡§§ ‡§Æ‡§∏‡•Ä‡§π‡§æ #‡§ö‡•Å‡§¶‡§ø‡§§ ‡§∞‡§æ‡§ú ‡§ú‡•Ä ‡§ï‡•ã ‡§ñ‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ #‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§è‡§µ‡§Ç #‡§™‡§≤‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡§≤‡•Ä ‡§¨‡§®‡§æ‡§è‡§Ç !!üôè \"‡§∏‡§≠‡•Ä #‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§è‡§Ç ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§\" #‡§â‡§¶‡§ø‡§§_‡§∞‡§æ‡§ú_‡§ï‡•ã_‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑_‡§¨‡§®‡§æ‡§ì_‡§¨‡•á @user  #CovidVaccine http   \n",
       "2770                                                2 /2ll‡§ï‡§π‡§æ‡§Å ‡§π‡•à? ‡§∏‡§®‡§¶ ‡§∞‡§π‡•á ‡§ï‡§ø ‡§Ø‡§π‡•Ä ‡§Ü‡§∞‡§ú‡•á‡§°‡•Ä ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§π‡•Ä ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Ü‡§∞‡§ú‡•á‡§°‡•Ä ‡§ï‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§Æ‡•Ä‡§∞‡§æ‡§® ‡§π‡•à‡§¶‡§∞ ‡§ï‡•Ä ‡§ó‡§ø‡§∞‡§´‡•ç‡§§‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§∞‡§ø‡§π‡§æ‡§à ‡§ï‡•á ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§ö‡•Å‡§™ ‡§π‡•à‡•§ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡•Ä ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•á‡§∞‡•á ‡§¨‡•Å‡§∞‡•á ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§®‡§π‡•Ä‡§Ç ‡§§‡•ã ‡§π‡§Æ ‡§Ü‡§™‡§ï‡§æ ‡§ù‡§Ç‡§°‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§¢‡•ã‡§è‡§Ç?  @user  @user   #JusticeForShahabuddin   \n",
       "2907                                                                                                                                                                                                                ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§∏‡§ø‡§µ‡§æ‡§® ‡§ï‡•á ‡§®‡§æ‡§Æ ‡§ï‡§∞ ‡§¶‡•Ä   ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§™‡§®‡•á ‡§∏‡§ø‡§µ‡§æ‡§® ‡§ï‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§® ‡§Æ‡§ø‡§≤ ‡§∏‡§ï‡•Ä üò≠  #JusticeForShahabuddin   \n",
       "\n",
       "      label  split  \n",
       "2721      0  train  \n",
       "2560      0  train  \n",
       "511       1  train  \n",
       "2770      0  train  \n",
       "2907      0  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KEN20_EN\n",
      "23192 entries, of which 11596 (50.00%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>Haisha? Move to japan you fucking fag. Hurr durr im an amine. Yeah fuck off you literal veggie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26524</th>\n",
       "      <td>Pussy so fat the bitch gave me STDs: Sexually Transmitted Diabetesüò≠</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>What up retard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18227</th>\n",
       "      <td>Ramazan has always proved a blessing for PAKISTAN. 27th Ramazan when Pakistan came into existence üòçüòçüáµüá∞üáµüá∞üíöüíö #ÿ™ÿ≠ŸÅ€Å_ÿ±ŸÖÿ∂ÿßŸÜ_Ÿæ€åÿßÿ±ÿß_Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>COME OUT TO THE BAY AREA AND GET UR COCK SUCKED REALL GOOD FAGGOT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text  \\\n",
       "1554                                         Haisha? Move to japan you fucking fag. Hurr durr im an amine. Yeah fuck off you literal veggie   \n",
       "26524                                                                   Pussy so fat the bitch gave me STDs: Sexually Transmitted Diabetesüò≠   \n",
       "2283                                                                                                                         What up retard   \n",
       "18227  Ramazan has always proved a blessing for PAKISTAN. 27th Ramazan when Pakistan came into existence üòçüòçüáµüá∞üáµüá∞üíöüíö #ÿ™ÿ≠ŸÅ€Å_ÿ±ŸÖÿ∂ÿßŸÜ_Ÿæ€åÿßÿ±ÿß_Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ   \n",
       "5685                                                                      COME OUT TO THE BAY AREA AND GET UR COCK SUCKED REALL GOOD FAGGOT   \n",
       "\n",
       "       label  \n",
       "1554       1  \n",
       "26524      1  \n",
       "2283       1  \n",
       "18227      0  \n",
       "5685       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUS19_AR\n",
      "3353 entries, of which 755 (22.52%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>@user @user ÿßÿÆÿ± ŸÖŸÜ Ÿäÿ™ŸÉŸÑŸÖ ÿßŸÜÿ™ŸÖ ŸäÿßÿÆŸàŸÜÿ© ŸàŸÑÿßŸÑŸÉŸÖ ÿØÿßÿ± ŸàŸÑÿß ÿ®ŸÑÿØ  ÿßŸÜÿ™ŸÖ ÿÆŸÜÿßÿ≤Ÿäÿ± ÿßŸÑÿ∫ÿ±ÿ® Ÿàÿ∑Ÿáÿ±ÿßŸÜ ŸàÿßŸÑÿ¥ÿ±ŸÅ ŸàÿßŸÑÿ∫Ÿäÿ±‚Ä¶ http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>ÿßŸä ÿßŸÖÿ±ÿ£ÿ© ŸÖÿ™ÿ®ÿ±ÿ¨ÿ© ŸÜÿßÿ≤ÿπÿ© ÿ≠ÿ¨ÿßÿ®Ÿáÿß ŸÑÿßÿ™ÿ¥ÿ±ŸÅŸÜÿß ŸÉÿß ÿ±ÿ¨ÿßŸÑ ŸàŸÑŸäÿ≥ ÿ∞ŸÉŸàÿ± ŸàŸÑŸÜ ŸÜŸÅŸÉÿ± ŸÜÿ±ÿ™ÿ®ÿ∑ ÿ®Ÿáÿß ÿßÿ¥ŸàŸÅŸáÿß ŸÜÿßÿ≤ÿπŸá ÿ≠ÿ¨ÿßÿ®Ÿáÿß ŸÉŸÖŸäÿ©‚Ä¶ http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>@user Ÿäÿß ÿ≠ŸÇŸäÿ± ŸáŸäÿØÿß ÿßŸÑÿπŸáÿØ ŸäŸÑŸä ÿßŸÜÿ™ ÿ®ÿØŸÉ ŸäŸÑŸä ÿßŸÜÿ™ ÿπŸëŸÖ ÿ™ÿ®Ÿàÿ≥ ÿ±ÿßÿµ ÿπŸàŸÜ Ÿäÿß Ÿàÿßÿ∑Ÿä Ÿäÿß ÿÆŸÜÿ≤Ÿäÿ±</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>ÿ™ÿÆŸäŸÑ ÿ®ŸÜŸÅÿ≥ ÿßŸÑŸàŸÇÿ™ ÿ™ŸÉŸÑŸÖ ÿÆŸÜÿ≤Ÿäÿ± ÿ®ÿßŸÑŸàÿßŸÇÿπ ŸàŸäÿ≥ÿ®ŸÉ ÿ≥ÿ®ŸàÿØÿ± ÿ®ÿßŸÑÿÆÿßÿµ ŸàŸäŸÖŸÜÿ¥ŸÜŸÉ Ÿàÿ≥ŸäŸÅ ÿü ÿßŸä ÿßŸÜÿ≠ÿ∑ÿßÿ∑ ÿ™ŸàÿµŸÑÿ™ ŸÑŸá Ÿäÿß ÿßŸÜÿß</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>ŸàŸÜŸáÿßŸäÿ™ŸÉŸÖ  ŸÇÿßÿØŸÖÿ© . ÿ¥ÿßÿ±ÿ®Ÿä ÿ®ŸàŸÑ ÿßŸÑÿ®ÿπŸäÿ± .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  \\\n",
       "1221      @user @user ÿßÿÆÿ± ŸÖŸÜ Ÿäÿ™ŸÉŸÑŸÖ ÿßŸÜÿ™ŸÖ ŸäÿßÿÆŸàŸÜÿ© ŸàŸÑÿßŸÑŸÉŸÖ ÿØÿßÿ± ŸàŸÑÿß ÿ®ŸÑÿØ  ÿßŸÜÿ™ŸÖ ÿÆŸÜÿßÿ≤Ÿäÿ± ÿßŸÑÿ∫ÿ±ÿ® Ÿàÿ∑Ÿáÿ±ÿßŸÜ ŸàÿßŸÑÿ¥ÿ±ŸÅ ŸàÿßŸÑÿ∫Ÿäÿ±‚Ä¶ http   \n",
       "1794  ÿßŸä ÿßŸÖÿ±ÿ£ÿ© ŸÖÿ™ÿ®ÿ±ÿ¨ÿ© ŸÜÿßÿ≤ÿπÿ© ÿ≠ÿ¨ÿßÿ®Ÿáÿß ŸÑÿßÿ™ÿ¥ÿ±ŸÅŸÜÿß ŸÉÿß ÿ±ÿ¨ÿßŸÑ ŸàŸÑŸäÿ≥ ÿ∞ŸÉŸàÿ± ŸàŸÑŸÜ ŸÜŸÅŸÉÿ± ŸÜÿ±ÿ™ÿ®ÿ∑ ÿ®Ÿáÿß ÿßÿ¥ŸàŸÅŸáÿß ŸÜÿßÿ≤ÿπŸá ÿ≠ÿ¨ÿßÿ®Ÿáÿß ŸÉŸÖŸäÿ©‚Ä¶ http   \n",
       "3186                             @user Ÿäÿß ÿ≠ŸÇŸäÿ± ŸáŸäÿØÿß ÿßŸÑÿπŸáÿØ ŸäŸÑŸä ÿßŸÜÿ™ ÿ®ÿØŸÉ ŸäŸÑŸä ÿßŸÜÿ™ ÿπŸëŸÖ ÿ™ÿ®Ÿàÿ≥ ÿ±ÿßÿµ ÿπŸàŸÜ Ÿäÿß Ÿàÿßÿ∑Ÿä Ÿäÿß ÿÆŸÜÿ≤Ÿäÿ±   \n",
       "2381             ÿ™ÿÆŸäŸÑ ÿ®ŸÜŸÅÿ≥ ÿßŸÑŸàŸÇÿ™ ÿ™ŸÉŸÑŸÖ ÿÆŸÜÿ≤Ÿäÿ± ÿ®ÿßŸÑŸàÿßŸÇÿπ ŸàŸäÿ≥ÿ®ŸÉ ÿ≥ÿ®ŸàÿØÿ± ÿ®ÿßŸÑÿÆÿßÿµ ŸàŸäŸÖŸÜÿ¥ŸÜŸÉ Ÿàÿ≥ŸäŸÅ ÿü ÿßŸä ÿßŸÜÿ≠ÿ∑ÿßÿ∑ ÿ™ŸàÿµŸÑÿ™ ŸÑŸá Ÿäÿß ÿßŸÜÿß   \n",
       "2017                                                                       ŸàŸÜŸáÿßŸäÿ™ŸÉŸÖ  ŸÇÿßÿØŸÖÿ© . ÿ¥ÿßÿ±ÿ®Ÿä ÿ®ŸàŸÑ ÿßŸÑÿ®ÿπŸäÿ± .   \n",
       "\n",
       "      label  \n",
       "1221      0  \n",
       "1794      0  \n",
       "3186      1  \n",
       "2381      0  \n",
       "2017      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUS19_FR\n",
      "4014 entries, of which 399 (9.94%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>@user @user un adepte du lieu commun gauchiste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>bravo au r√©alisateur de #lejouroujaibrulemoncoeur qui inclut le #harc√®lement #antisemite dans le film ¬´¬† #sale #juif¬†¬ª. une r√©alit√©.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>: [l'africain d'alg√©rie est souvent raciste sur twitter.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>une gauchiste reste une gauchiste. et pourtant elle bataill√©. http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>maitena biraben.. la rumeur raconte qu en bonne gauchiste elle pr√©voit de reverser l'int√©gralit√© de la somme √† des‚Ä¶ http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      text  \\\n",
       "1405                                                                                        @user @user un adepte du lieu commun gauchiste   \n",
       "2827  bravo au r√©alisateur de #lejouroujaibrulemoncoeur qui inclut le #harc√®lement #antisemite dans le film ¬´¬† #sale #juif¬†¬ª. une r√©alit√©.   \n",
       "2796                                                                              : [l'africain d'alg√©rie est souvent raciste sur twitter.   \n",
       "2734                                                                    une gauchiste reste une gauchiste. et pourtant elle bataill√©. http   \n",
       "1470              maitena biraben.. la rumeur raconte qu en bonne gauchiste elle pr√©voit de reverser l'int√©gralit√© de la somme √† des‚Ä¶ http   \n",
       "\n",
       "      label  \n",
       "1405      0  \n",
       "2827      0  \n",
       "2796      0  \n",
       "2734      0  \n",
       "1470      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAN20_IT\n",
      "8100 entries, of which 3388 (41.83%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>Vanno affondate. Hanno rotto i c.....i  Aquarius vuol dettare ancora legge: carica migranti e rifiuta gli ordini libici http</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>@user Mi chiedo come sia possibile definire Islam religione di pace invece di mettere in guardia il mondo da questa \"cultura\" subumana #sposebambine</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>Business immigrati Tanti ci guadagnano:  Le ONG che trasportano, Le Coop che ospitano, il caporalato, a breve l'industria con mano d'opera a basso costo, i Sindacati che da loro possono ripartire a vendere tessere, i partiti pro immigrazione che prenderanno i loro voti.</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>Se stranieri, delinquenti. Se italiani, derubricata a ragazzata e in premio non c'√® la medaglia di Salvini. √â l' Italietta legastellata.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>Scusate, ma a proposito di #facciamocome: non potremmo semplicemente espellere anche noi tutti gli stranieri disoccupati? (cos√¨ evitiamo anche il groviglio della discriminazione per il rdc)</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                text  \\\n",
       "4312                                                                                                                                                    Vanno affondate. Hanno rotto i c.....i  Aquarius vuol dettare ancora legge: carica migranti e rifiuta gli ordini libici http   \n",
       "4079                                                                                                                            @user Mi chiedo come sia possibile definire Islam religione di pace invece di mettere in guardia il mondo da questa \"cultura\" subumana #sposebambine   \n",
       "7379  Business immigrati Tanti ci guadagnano:  Le ONG che trasportano, Le Coop che ospitano, il caporalato, a breve l'industria con mano d'opera a basso costo, i Sindacati che da loro possono ripartire a vendere tessere, i partiti pro immigrazione che prenderanno i loro voti.   \n",
       "6723                                                                                                                                        Se stranieri, delinquenti. Se italiani, derubricata a ragazzata e in premio non c'√® la medaglia di Salvini. √â l' Italietta legastellata.   \n",
       "4355                                                                                   Scusate, ma a proposito di #facciamocome: non potremmo semplicemente espellere anche noi tutti gli stranieri disoccupati? (cos√¨ evitiamo anche il groviglio della discriminazione per il rdc)   \n",
       "\n",
       "      label  split  \n",
       "4312      1  train  \n",
       "4079      1  train  \n",
       "7379      0   test  \n",
       "6723      0  train  \n",
       "4355      1  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def descriptive_stats(df):\n",
    "    n_total = df.shape[0]\n",
    "    n_hate = df.label.sum()\n",
    "    print(\"{} entries, of which {} ({:.2%}) are hateful.\".format(n_total, n_hate, n_hate/n_total))\n",
    "    return df.label.sum()/len(df), len(df)\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    descriptive_stats(df_dict[dataset])\n",
    "    display(df_dict[dataset].sample(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c79d7f-8abc-4b7b-957d-073051f468fe",
   "metadata": {},
   "source": [
    "## Create and export splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99d2e82a-460f-4fe4-b777-fe34ae08c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 2k from each dataset for testing and 500 for dev\n",
    "# except for Ousidhoum in French and Arabic, where train set would otherwise be too small\n",
    "# and for HASOC 20 and 21 in Hindi, where test splits are given\n",
    "\n",
    "TEST_SIZE = 2000\n",
    "DEV_SIZE = 500\n",
    "\n",
    "for dataset in df_dict:\n",
    "    if \"ous19_fr\" in dataset:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = 2000, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = 1500, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_500.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_1500.csv\", index=False)\n",
    "    elif \"ous19_ar\" in dataset:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = 1300, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = 1000, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_300.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_1000.csv\", index=False)\n",
    "    elif \"has19_hi\" in dataset or \"has20_hi\" in dataset: # use provided test sets\n",
    "        df_dict[dataset][df_dict[dataset][\"split\"]==\"test\"].to_csv(f\"../0_data/main/1_clean/{dataset}/test_{len(df_dict[dataset][df_dict[dataset]['split']=='test'])}.csv\", index=False)\n",
    "        df_dict[dataset], devset = train_test_split(df_dict[dataset][df_dict[dataset][\"split\"]==\"train\"], test_size = 500, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_500.csv\", index=False)\n",
    "    else:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = TEST_SIZE+DEV_SIZE, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = TEST_SIZE, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_{DEV_SIZE}.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_{TEST_SIZE}.csv\", index=False)\n",
    "        \n",
    "# export all data that is not test or dev, so we can use it for full sample training\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset].to_csv(f\"../0_data/main/1_clean/{dataset}/train_{len(df_dict[dataset])}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da900890-72e9-4804-8570-6758c9d285bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAS19_ES\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "DYN21_EN\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 3000 training set\n",
      "  saving n = 4000 training set\n",
      "  saving n = 5000 training set\n",
      "  saving n = 10000 training set\n",
      "  saving n = 20000 training set\n",
      "\n",
      "FOR19_PT\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "FOU18_EN\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 3000 training set\n",
      "  saving n = 4000 training set\n",
      "  saving n = 5000 training set\n",
      "  saving n = 10000 training set\n",
      "  saving n = 20000 training set\n",
      "\n",
      "HAS19_HI\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "HAS20_HI\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "HAS21_HI\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "KEN20_EN\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 3000 training set\n",
      "  saving n = 4000 training set\n",
      "  saving n = 5000 training set\n",
      "  saving n = 10000 training set\n",
      "  saving n = 20000 training set\n",
      "\n",
      "OUS19_AR\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "OUS19_FR\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "SAN20_IT\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create differently-sized train portions from rest of data\n",
    "\n",
    "SEEDS = 10 # for repeated experiments with different random data selection\n",
    "N_RANGE = [10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, 10000, 20000]\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    for n in N_RANGE:\n",
    "        \n",
    "        # save all splits for English test sets\n",
    "        if n<len(df_dict[dataset]) and (\"dyn21\" in dataset or \"ken20\" in dataset or \"fou18\" in dataset): \n",
    "            print(f\"  saving n = {n} training set\")\n",
    "            for random_state in range(1, SEEDS+1):\n",
    "                df_dict[dataset].sample(n, random_state = random_state).to_csv(f\"../0_data/main/1_clean/{dataset}/train/train_{n}_rs{random_state}.csv\",index=False)\n",
    "        \n",
    "        # save splits up to 2k for other datasets\n",
    "        elif n<len(df_dict[dataset]) and n<=2000: \n",
    "            print(f\"  saving n = {n} training set\")\n",
    "            for random_state in range(1, SEEDS+1):  \n",
    "                df_dict[dataset].sample(n, random_state = random_state).to_csv(f\"../0_data/main/1_clean/{dataset}/train/train_{n}_rs{random_state}.csv\",index=False)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84561adf-666c-48d5-92c6-bce907d20301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate_detection_env_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
